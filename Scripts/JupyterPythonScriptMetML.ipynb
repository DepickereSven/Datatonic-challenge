{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanten\n",
    "BASIC_PATH = '../Data/'\n",
    "ALL_FILES = BASIC_PATH + '*.csv'\n",
    "\n",
    "from math import *\n",
    "\n",
    "\n",
    "usaStates = [\n",
    "    \"AL\",\n",
    "    \"AK\",\n",
    "    \"AZ\",\n",
    "    \"AR\",\n",
    "    \"CA\",\n",
    "    \"CO\",\n",
    "    \"CT\",\n",
    "    \"DE\",\n",
    "    \"FL\",\n",
    "    \"GA\",\n",
    "    \"HI\",\n",
    "    \"ID\",\n",
    "    \"IL\",\n",
    "    \"IN\",\n",
    "    \"IA\",\n",
    "    \"KS\",\n",
    "    \"KY\",\n",
    "    \"LA\",\n",
    "    \"ME\",\n",
    "    \"MD\",\n",
    "    \"MA\",\n",
    "    \"MI\",\n",
    "    \"MN\",\n",
    "    \"MS\",\n",
    "    \"MO\",\n",
    "    \"MT\",\n",
    "    \"NE\",\n",
    "    \"NV\",\n",
    "    \"NH\",\n",
    "    \"NJ\",\n",
    "    \"NM\",\n",
    "    \"NY\",\n",
    "    \"NC\",\n",
    "    \"ND\",\n",
    "    \"OH\",\n",
    "    \"OK\",\n",
    "    \"OR\",\n",
    "    \"PA\",\n",
    "    \"RI\",\n",
    "    \"SC\",\n",
    "    \"SD\",\n",
    "    \"TN\",\n",
    "    \"TX\",\n",
    "    \"UT\",\n",
    "    \"VT\",\n",
    "    \"VA\",\n",
    "    \"WA\",\n",
    "    \"WV\",\n",
    "    \"WI\",\n",
    "    \"WY\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zelf geschreven functies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "\n",
    "def readAllFiles():\n",
    "    files = glob.glob(ALL_FILES)\n",
    "    frames = []\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, index_col = 0)\n",
    "        frames.append(df)\n",
    "\n",
    "    return pd.concat(frames)\n",
    "\n",
    "def readOneFile(url):\n",
    "    return pd.read_csv(url, index_col = 0)\n",
    "\n",
    "def exportDfToCsvFiles(df):\n",
    "    step = 1000000\n",
    "    start = 0\n",
    "    stop = step\n",
    "    i = 0\n",
    "\n",
    "    while start < len(df):\n",
    "        if stop >= len(df):\n",
    "            stop = len(df)\n",
    "        fileName = BASIC_PATH +  'flights_2010_' + str(i) + '.csv'\n",
    "        \n",
    "        data = df.iloc[start:stop, 0:]\n",
    "        data.to_csv( fileName, sep=',')\n",
    "\n",
    "        start += step\n",
    "        stop += step\n",
    "        i += 1\n",
    "        \n",
    "def deleteWrongStates(df):\n",
    "    print(\"Aantal records:\", len(df))\n",
    "    copy = df\n",
    "    \n",
    "    for el in copy.departure_state.unique():\n",
    "        if(el not in usaStates):\n",
    "            copy = copy.drop(copy[copy['departure_state'] == el].index)\n",
    "    print(\"Aantal records na verwijderen foute vertrek staat:\", len(copy))\n",
    "\n",
    "    for el in copy.arrival_state.unique():\n",
    "        if(el not in usaStates):\n",
    "            copy = copy.drop(copy[copy['arrival_state'] == el].index)\n",
    "    print(\"Aantal records na verwijderen foute aankomst staat:\", len(copy))\n",
    "          \n",
    "    return copy\n",
    "\n",
    "def convertColumnTypes(df):\n",
    "    df.departure_schedule = df.departure_schedule.astype(int)\n",
    "    df.departure_delay = df.departure_delay.astype(float)\n",
    "    df.arrival_schedule = df.arrival_schedule.astype(int)\n",
    "    df.arrival_delay = df.arrival_delay.astype(float)\n",
    "    df.arrival_actual = df.arrival_actual.astype(int)\n",
    "    df.departure_actual = df.departure_actual.astype(int)\n",
    "    return df\n",
    "\n",
    "def dropMoreAdvancedDuplicates(df):\n",
    "    copy = df\n",
    "    copy = copy.groupby(['date', 'airline', 'airline_code', 'departure_airport', 'departure_state', 'departure_lat', 'departure_lon', 'departure_schedule', 'arrival_airport', 'arrival_state', 'arrival_lat', 'arrival_lon', 'arrival_schedule']).mean().reset_index()\n",
    "    copy = convertColumnTypes(copy)\n",
    "    copy = copy.drop(['index'], axis=1) #remove old index\n",
    "    return copy\n",
    "\n",
    "def calcDistance(df):\n",
    "    array = [];\n",
    "    for index, row in df.iterrows():\n",
    "        array.append(calcTheDistance(row))\n",
    "    return array;\n",
    "\n",
    "def calcTheDistance(el):\n",
    "    slat = radians(float(el[\"arrival_lat\"]))\n",
    "    slon = radians(float(el[\"arrival_lon\"]))\n",
    "    elat = radians(float(el[\"departure_lat\"]))\n",
    "    elon = radians(float(el[\"departure_lon\"]))\n",
    "    return 6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon))\n",
    "\n",
    "def calcTheTime(data):\n",
    "    durations = []\n",
    "    for i, row in data.iterrows():\n",
    "        duration = calcDuration(row[\"departure_schedule\"], row[\"arrival_schedule\"])\n",
    "        durations.append(duration)\n",
    "    return durations\n",
    "\n",
    "def getTotalMinutes(time):\n",
    "    time_str = str(int(time))\n",
    "    if len(time_str) == 4:\n",
    "        hours = time_str[0:2]\n",
    "    else:\n",
    "        hours = time_str[0:1]\n",
    "    hours = int(hours)\n",
    "        \n",
    "    minutes = int(time_str[-2:])\n",
    "    totalMinutes = minutes + hours * 60\n",
    "    return totalMinutes\n",
    "\n",
    "def getStringTime(totalMinutes):\n",
    "    hours = math.floor(totalMinutes / 60)\n",
    "    minutes = totalMinutes - (hours * 60)\n",
    "    return str(hours) + \":\" + str(minutes)\n",
    "\n",
    "def calcDuration(departure_schedule, arrival_schedule):\n",
    "    departure = getTotalMinutes(departure_schedule)\n",
    "    arrival = getTotalMinutes(arrival_schedule)\n",
    "    if arrival <= departure:\n",
    "        return (24 * 60) - (departure - arrival)\n",
    "    else:\n",
    "        return arrival - departure\n",
    "    \n",
    "def calcSpeeds(data):\n",
    "    speeds = []\n",
    "    for i, row in data.iterrows():\n",
    "        speed = row[\"distance\"] / (row[\"duration\"] / 60)\n",
    "        speeds.append(speed)\n",
    "    return speed\n",
    "\n",
    "def isNormalSpeed(speed, distance):\n",
    "    return (speed > 450 and speed <=1100) or (speed / distance) >= 1 and (speed / distance) <= 2 and speed <= 1100;\n",
    "\n",
    "def calcNormalSpeed(data):\n",
    "    isNormalSpeeds = []\n",
    "    for i, row in data.iterrows():\n",
    "        isNormalSpeeds.append(isNormalSpeed(row[\"speed\"], row[\"distance\"]))\n",
    "    return isNormalSpeeds;\n",
    "\n",
    "def cleanData(df):\n",
    "    print(\"Aantal records om te beginnen:\", len(df))\n",
    "    copy = df\n",
    "    \n",
    "    copy = copy.drop_duplicates()\n",
    "    print(\"Aantal records na verwijderen van dubbels:\", len(copy))\n",
    "    \n",
    "    copy = copy.reset_index()\n",
    "    print(\"Aantal records na nieuwe index:\", len(copy))\n",
    "    \n",
    "    copy = copy.dropna()\n",
    "    print(\"Aantal records na verwijderen lege waarden:\", len(copy))\n",
    "    \n",
    "    copy = deleteWrongStates(copy)\n",
    "    copy = convertColumnTypes(copy)\n",
    "    \n",
    "    copy = dropMoreAdvancedDuplicates(copy)\n",
    "    print(\"Aantal records na het verwijderen van de verborgen dubbels:\", len(copy))\n",
    "    \n",
    "    distance = calcDistance(copy)\n",
    "\n",
    "    copy['distance'] = distance\n",
    "    \n",
    "    durations = calcTheTime(copy)\n",
    "    \n",
    "    copy[\"duration\"] = durations\n",
    "    \n",
    "    speeds = calcSpeeds(copy)\n",
    "    \n",
    "    copy[\"speed\"] = speeds\n",
    "    \n",
    "    isNormalSpeeds = calcNormalSpeed(copy)\n",
    "    \n",
    "    copy[\"isNormalSpeed\"] = isNormalSpeeds\n",
    "    \n",
    "    copy = copy[copy[\"isNormalSpeed\"] == True]\n",
    "    \n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal records om te beginnen: 10642028\n",
      "Aantal records na verwijderen van dubbels: 10642028\n",
      "Aantal records na nieuwe index: 10642028\n",
      "Aantal records na verwijderen lege waarden: 10642028\n",
      "Aantal records: 10642028\n",
      "Aantal records na verwijderen foute vertrek staat: 10642028\n",
      "Aantal records na verwijderen foute aankomst staat: 10642028\n",
      "Aantal records na het verwijderen van de verborgen dubbels: 10642028\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'isNormalSpeed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cecb62680df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadAllFiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-d04e358bd4c5>\u001b[0m in \u001b[0;36mcleanData\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"speed\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[0misNormalSpeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcNormalSpeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"isNormalSpeed\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misNormalSpeeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d04e358bd4c5>\u001b[0m in \u001b[0;36mcalcNormalSpeed\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0misNormalSpeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0misNormalSpeeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misNormalSpeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"speed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0misNormalSpeeds\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'isNormalSpeed' is not defined"
     ]
    }
   ],
   "source": [
    "df = readAllFiles()\n",
    "df2 = cleanData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-0.00441251 -0.01723296 -0.00230018 -0.00156591]]\n",
      "Mean squared error: 1329.10\n",
      "Variance score: 0.00061\n",
      "0.000613246714151\n"
     ]
    }
   ],
   "source": [
    "# ML\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "enc = LabelEncoder();\n",
    "\n",
    "X = df.loc[:,['date', 'airline', 'departure_airport', 'arrival_airport']]\n",
    "X.date = enc.fit_transform(X.date)\n",
    "X.airline = enc.fit_transform(X.airline)\n",
    "X.departure_airport = enc.fit_transform(X.departure_airport)\n",
    "X.arrival_airport = enc.fit_transform(X.arrival_airport)\n",
    "\n",
    "y = df.loc[:,['arrival_delay']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', model.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_predict))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.5f' % r2_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "# ML model 2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "enc = LabelEncoder();\n",
    "\n",
    "X = df.loc[:,['date', 'airline', 'departure_airport', 'arrival_airport']]\n",
    "X.date = enc.fit_transform(X.date)\n",
    "X.airline = enc.fit_transform(X.airline)\n",
    "X.departure_airport = enc.fit_transform(X.departure_airport)\n",
    "X.arrival_airport = enc.fit_transform(X.arrival_airport)\n",
    "\n",
    "y = df.loc[:,['arrival_delay']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_predict))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.5f' % r2_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exportDfToCsvFiles(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a json file\n",
    "df2.to_json('flights_2010_file_time_update_good_data.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_code</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>departure_state</th>\n",
       "      <th>departure_lat</th>\n",
       "      <th>departure_lon</th>\n",
       "      <th>departure_schedule</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_state</th>\n",
       "      <th>arrival_lat</th>\n",
       "      <th>arrival_lon</th>\n",
       "      <th>arrival_schedule</th>\n",
       "      <th>departure_actual</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>arrival_actual</th>\n",
       "      <th>arrival_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, airline, airline_code, departure_airport, departure_state, departure_lat, departure_lon, departure_schedule, arrival_airport, arrival_state, arrival_lat, arrival_lon, arrival_schedule, departure_actual, departure_delay, arrival_actual, arrival_delay]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Controleer of er records zijn die een vertrektijd hebben die vroeger is dan de aankomsttijd\n",
    "# Omdat de aankomstdatum niet bijgehouden wordt, kan je niet zeker zijn of het de volgende dag is een een fout record\n",
    "# Daarom controleren we ook nog of de geplande vliegtijd meer dan x aantal minuten te snel is\n",
    "# We hebben geen extreme waardes gevonden en daarom geen records verwijderd\n",
    "df2[(df2.departure_schedule > df2.arrival_schedule) & ((df2.arrival_delay - df2.departure_delay) < -80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting SouthWest Airlines\n",
    "df_southWest = df2.loc[df['airline'] == \"WN\"]\n",
    "#selecting Alaska Airlines\n",
    "df_alaska = df2.loc[df['airline'] == \"AS\"]\n",
    "#selecting Hawaiian Airlines\n",
    "df_hawaiian = df2.loc[df['airline'] == \"HA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_southWest = df_southWest[['date', 'departure_airport','departure_state',\n",
    "                          'departure_lat', 'departure_lon',\n",
    "                          'arrival_airport', 'arrival_state',\n",
    "                          'arrival_lat', 'arrival_lon']]\n",
    "df_alaska = df_alaska[['date', 'departure_airport','departure_state',\n",
    "                          'departure_lat', 'departure_lon',\n",
    "                          'arrival_airport', 'arrival_state',\n",
    "                          'arrival_lat', 'arrival_lon']]\n",
    "df_hawaiian = df_hawaiian[['date', 'departure_airport','departure_state',\n",
    "                          'departure_lat', 'departure_lon',\n",
    "                          'arrival_airport', 'arrival_state',\n",
    "                          'arrival_lat', 'arrival_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a json file for SouthWest Airlines\n",
    "df_southWest.to_json('SouthWest_Airlines.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a json file for Alaska Airlines\n",
    "df_southWest.to_json('Alaska_Airlines.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a json file for Hawaiian Airlines\n",
    "df_southWest.to_json('Hawaiian_Airlines.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
